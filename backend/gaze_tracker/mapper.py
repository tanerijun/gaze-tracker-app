import json
from typing import Dict, Tuple

import cv2
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression

from .gaze_estimator import RoboflowGazeEstimator


class GazeMapper:
    """
    Maps gaze vectors to screen coordinates using linear regression.
    """

    def __init__(self):
        self.model_x = LinearRegression()
        self.model_y = LinearRegression()
        self.screen_size: Dict[str, int] | None = None
        self.calibration_data: pd.DataFrame | None = None

    def train(self) -> Tuple[float, float]:
        """
        Train the mapping model using calibration dataset generated by generate_calibration_data.

        Returns:
            Tuple[float, float]: R² scores for x and y coordinates
        """
        if self.screen_size is None or self.calibration_data is None:
            raise ValueError("Calibration data must be loaded before training.")

        df = self.calibration_data

        # Prepare features (gaze vectors) and labels (screen coordinates)
        X = df[["gaze_x", "gaze_y", "gaze_z"]].values
        _y = df[["point_x", "point_y"]].values

        y_x = df["point_x"].values
        y_y = df["point_y"].values

        self.model_x.fit(X, y_x)
        self.model_y.fit(X, y_y)

        # Return R² scores
        return (float(self.model_x.score(X, y_x)), float(self.model_y.score(X, y_y)))

    def predict(self, gaze_vector: np.ndarray) -> np.ndarray:
        """
        Maps gaze vector to screen coordinates.

        Args:
            gaze_vector: 3D gaze vector [x, y, z]

        Returns:
            np.ndarray: Predicted screen coordinates [x, y]
        """
        X = gaze_vector.reshape(1, -1)
        return np.array([self.model_x.predict(X)[0], self.model_y.predict(X)[0]])

    def load_calibration_data(
        self,
        video_path: str,
        calibration_data_path: str,
        frame_window: int = 5,
    ):
        """
        Load calibration data by extracting frames around each calibration point click.
        And save the data as property of the class.

        Args:
            video_path: Path to webcam recording
            calibration_data_path: Path to calibration JSON data
            frame_window: Number of frames to extract before/after each click
        """
        video = cv2.VideoCapture(video_path)
        if not video.isOpened():
            raise ValueError(f"Could not open video: {video_path}")

        fps = video.get(cv2.CAP_PROP_FPS)
        frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))

        with open(calibration_data_path) as f:
            calib_data = json.load(f)

        self.screen_size = {
            "width": calib_data["screenSize"]["width"],
            "height": calib_data["screenSize"]["height"],
        }

        dataset = []
        gaze_estimator = RoboflowGazeEstimator()

        for point in calib_data["points"]:
            timestamp_sec = point["timestamp"] / 1000.0
            click_frame = int(timestamp_sec * fps)

            # Calculate frame range
            start_frame = max(0, click_frame - frame_window)
            end_frame = min(frame_count - 1, click_frame + frame_window)

            video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            for frame_idx in range(start_frame, end_frame + 1):
                ret, frame = video.read()
                if not ret:
                    break

                _, gaze_vector = gaze_estimator.process_frame(frame)

                dataset.append(
                    {
                        "frame": frame_idx,
                        "point_x": point["x"],
                        "point_y": point["y"],
                        "gaze_x": gaze_vector[0],
                        "gaze_y": gaze_vector[1],
                        "gaze_z": gaze_vector[2],
                    }
                )

        video.release()

        df = pd.DataFrame(dataset)
        self.calibration_data = df
